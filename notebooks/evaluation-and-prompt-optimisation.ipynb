{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "69e0f8b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import anytree\n",
    "from anytree import Node,RenderTree\n",
    "\n",
    "openai.api_key  = os.environ.get('API_KEY')\n",
    "print(openai.api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15d9e315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to get completion from model based on a prompt input; model to be call can be changed for example GTP-3.5-turbo instead of GPT-4\n",
    "\n",
    "def get_completion(prompt, model=\"gpt-4\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0, # this is the degree of randomness of the model's output\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ef22a6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript = f\"\"\"\n",
    "P1: \"Have you all been following the news about the rising sea levels? Our coastal cities are under threat and we can't just sit and watch. We need to be proactive in our mitigation efforts, perhaps even consider relocating our operations to a safer, inland location.\" P2: \"I share your concerns, P1, but relocating seems a bit extreme, doesn't it? It's a costly measure. I think we should focus on increasing our preparedness for extreme weather events. Let's reinforce our infrastructure, have contingency plans in place. Better safe than sorry, right?\" P3: \"While I appreciate both points, I must stress that we can't tackle this issue single-handedly. We need to lobby for more robust government measures. It's a national issue.\" P4: \"Indeed, P3. But we also have a responsibility to reduce our own carbon footprint. Maybe, investing in green technologies or shifting to cleaner production methods?\" P5: \"I like that idea, P4. In fact, it might even prove to be beneficial for our brand image. We can portray ourselves as a responsible, environmentally-conscious corporation.\" P6: \"All points considered, we need to come up with a comprehensive plan. Let's get our teams on this - risk management, PR, everyone. And let's engage with local communities, they need to be part of this conversation too.\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa458689",
   "metadata": {},
   "source": [
    "# 0 Testing execution time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5adcb3ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello world\n",
      "Execution time: 2.0000510215759277 seconds\n"
     ]
    }
   ],
   "source": [
    "# Testing time needed for basic prompt completion via OpenAI API\n",
    "prompt = \"Say 'hello world'\"\n",
    "start_time = time.time()\n",
    "output = get_completion(prompt)\n",
    "end_time = time.time()\n",
    "print(output)\n",
    "print(f\"Execution time: {end_time - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2fd0415c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sea level concerns\n",
      "Execution time: 1.991041660308838 seconds\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Summarize the {transcript} in three words\n",
    "\"\"\"\n",
    "start_time = time.time()\n",
    "output = get_completion(prompt)\n",
    "end_time = time.time()\n",
    "print(output)\n",
    "print(f\"Execution time: {end_time - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "acc40dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rising sea levels, proactive mitigation, comprehensive plan.\n",
      "Execution time: 2.161013603210449 seconds\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Summarize the {transcript} in six words\n",
    "\"\"\"\n",
    "start_time = time.time()\n",
    "output = get_completion(prompt)\n",
    "end_time = time.time()\n",
    "print(output)\n",
    "print(f\"Execution time: {end_time - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56903f7a",
   "metadata": {},
   "source": [
    "# Feature 1 -Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1aafa08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for getting completion from OpenAI instructing model to identify topics based on a discussion transcript\n",
    "# End-of-week-one prompt (by Armando)\n",
    "def get_topics(transcript):\n",
    "\n",
    "    prompt_topic = f\"\"\"\n",
    "    You are an assistant for group discussions, specializing in keeping track of and documenting the discussion,/\n",
    "    that is, the topics discussed, the viewpoints/positions on each topic, and the arguments/explanations given in support of each viewpoint./\n",
    "\n",
    "    Identify the topics discussed in the discussion transcript, delimited with triple backticks.\n",
    "\n",
    "    Check the following steps but don't print each step only print what is asked:\n",
    "\n",
    "    Step 1: Identify the topics discussed in the discussion transcript. Take the time to read the complete transcript, don't\n",
    "            take words as a whole argument, analyze the complete argument and then decide on the topic.\\\n",
    "    Step 2: Analyze each topic (if there is more than one), and merge those into only one main topic.\n",
    "            If there are topics that are as important as the main topic, display them as a second topic but only if it is not linked to the\n",
    "            main topic of discussion in the transcript. Only in this case, you can display more topics.\\\n",
    "    Step 3: Extract the statements related to each topic.\\\n",
    "    Step 4: State the necessary main topics of the entire transcript in a concise, descriptive sentence,\n",
    "            in up to 3 words for each topic.\\\n",
    "    Step 5: Provide the output in a JSON format where the key is the topic and the value is a list of statements made by the\n",
    "            participants.\\\n",
    "\n",
    "    Review transcript: '''{transcript}'''\n",
    "    \"\"\"\n",
    "\n",
    "    topics = get_completion(prompt_topic)\n",
    "    topics_json = json.loads(topics)\n",
    "\n",
    "    return topics_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "7777c356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Animal Testing': ['Animal testing is necessary for medical research. It has contributed to numerous medical advancements and the development of life-saving treatments.', 'While I understand the importance of medical research, we should also consider the ethical concerns associated with animal testing. Animals deserve to be treated with compassion and should not suffer for the sake of human benefits.', 'There are alternatives to animal testing, such as in vitro testing and computer simulations, that can provide reliable results without causing harm to animals. We should prioritize the development and adoption of these alternatives.', 'Animal testing should be regulated and minimized, but we cannot completely eliminate it at this stage. Striking a balance between scientific progress and animal welfare is crucial.', 'We need more transparency and accountability in animal testing. Researchers should provide clear justifications for using animals and ensure that it is conducted in the most humane way possible.']}\n",
      "Execution time: 32.40483736991882 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "topics = get_topics(transcript)\n",
    "end_time = time.time()\n",
    "print(topics)\n",
    "print(f\"Execution time: {end_time - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "ba734062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Animal Testing'])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ce25379a",
   "metadata": {},
   "outputs": [],
   "source": [
    "###SEEMS TO BE WORKING QUITE WELL\n",
    "### Topics only, without corresponding transcripts\n",
    "def get_topics(transcript):\n",
    "\n",
    "    prompt_topic = f\"\"\"\n",
    "    You are an assistant for group discussions, specializing in keeping track of and documenting the discussion,/\n",
    "    that is, the topics discussed, the viewpoints/positions on each topic, and the arguments/explanations given in support of each viewpoint./\n",
    "\n",
    "    Identify the one or several main topics discussed in the discussion transcript, delimited with triple backticks. If there are multiple identified topics, but they all center around the same main topic, only record the main topic.\n",
    "    \n",
    "    Provide the output in JSON-format.\n",
    "\n",
    "    Review transcript: '''{transcript}'''\n",
    "    \"\"\"\n",
    "\n",
    "    topics = get_completion(prompt_topic)\n",
    "    topics_json = json.loads(topics)\n",
    "\n",
    "    return topics_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e92e441",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the following steps but don't print each step only print what is asked:\n",
    "\n",
    " #   Step 1: Identify the topics discussed in the discussion transcript. Take the time to read the complete transcript, don't\n",
    "  #          take words as a whole argument, analyze the complete argument and then decide on the main topic.\\\n",
    "   # Step 2: Ff there is more than potential main topic, analyse each potential topic and the corresponding participant statements, and merge those into only one main topic, unless they are entirely separate discussion topics and are not building on each other.\n",
    "    #        If there are topics that are as important as the main topic, display them as a second topic but only if it is not linked to the\n",
    "     #       main topic of discussion in the transcript. Only in this case, you can display more topics.\\\n",
    "    #Step 3: State the necessary main topics of the entire transcript in a concise, descriptive sentence,\n",
    "            in up to 3 words for each topic.\\\n",
    "    #Step 4: Provide the output in a JSON format.\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0b2f7a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'main_topic': 'Rising sea levels and mitigation efforts for coastal cities'}\n",
      "Execution time: 3.6619114875793457 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "topics = get_topics(transcript)\n",
    "end_time = time.time()\n",
    "print(topics)\n",
    "print(f\"Execution time: {end_time - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "86be2e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimized prompt\n",
    "def get_topics(transcript):\n",
    "\n",
    "    prompt_topic = f\"\"\"\n",
    "As an assistant for group discussions, your task is to analyze and document the topics discussed, viewpoints/positions on each topic, and arguments/explanations given in support of each viewpoint. Your task includes the following steps:\n",
    "\n",
    "Step 1: Read the complete discussion {transcript} and identify the topics discussed. Analyze each argument and decide on the topic covered.\n",
    "\n",
    "Step 2: If there is more than one topic, merge them into a main topic. You may only include secondary topics if they are entirely unrelated to the main topic of discussion.\n",
    "\n",
    "Step 3: Extract the statements related to each identified topic.\n",
    "\n",
    "Step 4: State the main topics of the entire transcript in a concise, descriptive sentence, using up to 3 words for each topic.\n",
    "\n",
    "Step 5: Provide the output in a JSON format where the key is the topic and the value is a list of statements made by the participants.\n",
    "\n",
    "Please note that your response should be accurate, concise, and clear. You should focus on providing a comprehensive analysis of the discussion and its topics, while also ensuring that your output is easily understandable.    \n",
    "\"\"\"\n",
    "\n",
    "    topics = get_completion(prompt_topic)\n",
    "    topics_json = json.loads(topics)\n",
    "\n",
    "    return topics_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "21a30bd1",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Population Growth': [\"What are we gonna do about the rising population? We can't keep up.\", 'What about promoting family planning programs? It has worked in some countries.'], 'Public Services': ['We could start by improving our public services, specifically health and education.'], 'Immigration': ['I think immigration policies should be stricter. There are too many people coming in.'], 'Job Creation': ['Wait, but what if we focus on creating more jobs? More people means more workforce.'], 'Housing': [\"Let's not forget about housing. We need more and affordable homes.\"], 'Environment': [\"The environment! We can't ignore the impact of population growth on nature.\"]}\n",
      "Execution time: 28.45951771736145 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "topics = get_topics(transcript)\n",
    "end_time = time.time()\n",
    "print(topics)\n",
    "print(f\"Execution time: {end_time - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "96ca3632",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Population Growth', 'Public Services', 'Immigration', 'Job Creation', 'Housing', 'Environment'])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c4ea7d47",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello world!\n",
      "Execution time basic prompt: 0.7153444290161133 seconds\n",
      "Population solutions brainstorming.\n",
      "Execution time 3-word summary: 1.32914137840271 seconds\n",
      "Ideas for addressing population growth concerns.\n",
      "Execution time 6-word summary: 1.2478251457214355 seconds\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[85], line 65\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m topics_json\n\u001b[1;32m     64\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 65\u001b[0m topics \u001b[38;5;241m=\u001b[39m \u001b[43mget_topics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtranscript\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28mprint\u001b[39m(topics)\n",
      "Cell \u001b[0;32mIn[85], line 60\u001b[0m, in \u001b[0;36mget_topics\u001b[0;34m(transcript)\u001b[0m\n\u001b[1;32m     37\u001b[0m prompt_topic \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;124mYou are an assistant for group discussions, specializing in keeping track of and documenting the discussion,/\u001b[39m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;124mthat is, the topics discussed, the viewpoints/positions on each topic, and the arguments/explanations given in support of each viewpoint./\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;124mReview transcript: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtranscript\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;124m\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     59\u001b[0m topics \u001b[38;5;241m=\u001b[39m get_completion(prompt_topic)\n\u001b[0;32m---> 60\u001b[0m topics_json \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtopics\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m topics_json\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[1;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/json/decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscan_once(s, idx)\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "#using gpt 3.5 turbo [observation: gpt3.5 almost takes the same time, but doesn't manage to output in right JSON-format]\n",
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0, # this is the degree of randomness of the model's output\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]\n",
    "\n",
    "# Testing time needed for basic prompt completion via OpenAI API\n",
    "prompt = \"Say 'hello world'\"\n",
    "start_time = time.time()\n",
    "output = get_completion(prompt)\n",
    "end_time = time.time()\n",
    "print(output)\n",
    "print(f\"Execution time basic prompt: {end_time - start_time} seconds\")\n",
    "\n",
    "\n",
    "prompt = f\"\"\"Summarize the {transcript} in three words\"\"\"\n",
    "start_time = time.time()\n",
    "output = get_completion(prompt)\n",
    "end_time = time.time()\n",
    "print(output)\n",
    "print(f\"Execution time 3-word summary: {end_time - start_time} seconds\")\n",
    "\n",
    "\n",
    "prompt = f\"\"\"Summarize the {transcript} in six words\"\"\"\n",
    "start_time = time.time()\n",
    "output = get_completion(prompt)\n",
    "end_time = time.time()\n",
    "print(output)\n",
    "print(f\"Execution time 6-word summary: {end_time - start_time} seconds\")\n",
    "\n",
    "def get_topics(transcript):\n",
    "\n",
    "    prompt_topic = f\"\"\"\n",
    "    You are an assistant for group discussions, specializing in keeping track of and documenting the discussion,/\n",
    "    that is, the topics discussed, the viewpoints/positions on each topic, and the arguments/explanations given in support of each viewpoint./\n",
    "\n",
    "    Identify the topics discussed in the discussion transcript, delimited with triple backticks.\n",
    "\n",
    "    Check the following steps but don't print each step only print what is asked:\n",
    "\n",
    "    Step 1: Identify the topics discussed in the discussion transcript. Take the time to read the complete transcript, don't\n",
    "            take words as a whole argument, analyze the complete argument and then decide on the topic.\\\n",
    "    Step 2: Analyze each topic (if there is more than one), and merge those into only one main topic.\n",
    "            If there are topics that are as important as the main topic, display them as a second topic but only if it is linked to the\n",
    "    main topic of discussion in the transcript. Only in this case, you can display more topics.\\\n",
    "    Step 3: Extract the statements related to each topic.\\\n",
    "    Step 4: State the necessary main topics of the entire transcript in a concise, descriptive sentence,\n",
    "            in up to 3 words for each topic.\\\n",
    "    Step 5: Provide the output in a JSON format where the key is the topic and the value is a list of statements made by the\n",
    "            participants.\\\n",
    "\n",
    "    Review transcript: '''{transcript}'''\n",
    "    \"\"\"\n",
    "\n",
    "    topics = get_completion(prompt_topic)\n",
    "    topics_json = json.loads(topics)\n",
    "\n",
    "    return topics_json\n",
    "\n",
    "start_time = time.time()\n",
    "topics = get_topics(transcript)\n",
    "end_time = time.time()\n",
    "print(topics)\n",
    "print(f\"Execution time topics: {end_time - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ace7be97",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Topic 1\": \"Animal Testing\",\n",
      "  \"Topic 2\": \"Medical Research\"\n",
      "}\n",
      "\n",
      "{\n",
      "  \"Statements for Topic 1\": [\n",
      "    \"Animal testing is necessary for medical research.\",\n",
      "    \"Ethical concerns associated with animal testing.\",\n",
      "    \"Alternatives to animal testing.\",\n",
      "    \"Regulation and minimization of animal testing.\",\n",
      "    \"Transparency and accountability in animal testing.\"\n",
      "  ],\n",
      "  \"Statements for Topic 2\": [\n",
      "    \"Contributed to numerous medical advancements.\",\n",
      "    \"Development of life-saving treatments.\",\n",
      "    \"Striking a balance between scientific progress and animal welfare.\"\n",
      "  ]\n",
      "}"
     ]
    }
   ],
   "source": [
    "# streaming (https://github.com/tmgthb/Stream-responses/blob/main/streams.ipynb)\n",
    "    \n",
    "### STREAM GPT-4 API RESPONSES\n",
    "delay_time = 0.01 #  faster\n",
    "max_response_length = 8000\n",
    "answer = ''\n",
    "\n",
    "prompt = f\"\"\"\n",
    "You are an assistant for group discussions, specializing in keeping track of and documenting the discussion,/\n",
    "that is, the topics discussed, the viewpoints/positions on each topic, and the arguments/explanations given in support of each viewpoint./\n",
    "\n",
    "Identify the topics discussed in the discussion transcript, delimited with triple backticks.\n",
    "\n",
    "Check the following steps but don't print each step only print what is asked:\n",
    "\n",
    "Step 1: Identify the topics discussed in the discussion transcript. Take the time to read the complete transcript, don't\n",
    "            take words as a whole argument, analyze the complete argument and then decide on the topic.\\\n",
    "Step 2: Analyze each topic (if there is more than one), and merge those into only one main topic.\n",
    "            If there are topics that are as important as the main topic, display them as a second topic but only if it is not linked to the\n",
    "            main topic of discussion in the transcript. Only in this case, you can display more topics.\\\n",
    "Step 3: Extract the statements related to each topic.\\\n",
    "\n",
    "Step 4: State the necessary main topics of the entire transcript in a concise, descriptive sentence,\n",
    "            in up to 3 words for each topic.\\\n",
    "\n",
    "Step 5: Provide the output in two dictionaries in JSON format where the key the first dictionary containts topics and the second dictionary the corresponding statements made by the\n",
    "            participants.\\\n",
    "\n",
    "Review transcript: '''{transcript}'''\n",
    "\"\"\"\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "# GPT-4 API REQUEST\n",
    "    model='gpt-4',\n",
    "    messages=[\n",
    "        {'role': 'user', 'content': f'{prompt}'}\n",
    "    ],\n",
    "    temperature=0,\n",
    "    stream=True,  # this time, we set stream=True\n",
    ")\n",
    "\n",
    "for event in response: \n",
    "    # STREAM THE ANSWER\n",
    "    print(answer, end='', flush=True) # Print the response    \n",
    "    # RETRIEVE THE TEXT FROM THE RESPONSE\n",
    "    event_time = time.time() - start_time  # CALCULATE TIME DELAY BY THE EVENT\n",
    "    event_text = event['choices'][0]['delta'] # EVENT DELTA RESPONSE\n",
    "    answer = event_text.get('content', '') # RETRIEVE CONTENT\n",
    "    time.sleep(delay_time)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "37d28563",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = get_topics(transcript)\n",
    "print(topics, end='', flush=True) # Print the response "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28205c2c",
   "metadata": {},
   "source": [
    "# Feature 2 - Viewpoints "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bf584f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for getting completion from OpenAI instructing model to identify viewpoints per topic based on output from get_topics\n",
    "\n",
    "def get_viewpoints_by_topic(topics,transcript):\n",
    "    result = {}\n",
    "    for topic, excerpt in topics.items():\n",
    "        prompt = f\"\"\"\n",
    "        You are an assistant for group discussions, specialized on keeping track and documenting the discussion,\n",
    "        that is, the topics discussed, the viewpoints/positions on each topic and the arguments/explanations given in support of each viewpoint.\n",
    "        For the topic \"{topic}\"elimited by triple hashtags, analyse the corresponding excerpt from the discussion.\n",
    "        Your task is to identify all the viewpoints expressed on the topic.\n",
    "\n",
    "        Proceed according to the following steps:\n",
    "\n",
    "        Step 1: In the below discussion transcript, delimited by triple backticks,\n",
    "                locate the excerpt corresponding to the topic and consider the rest\n",
    "                of the transcript as context for the subsequent steps.\n",
    "        Step 2: Are there one or several viewpoints being expressed in the excerpt?\n",
    "                A \"viewpoint\" refers to \"one's perspective of opinion on a particular topic\".\n",
    "        Step 3: If there is only one viewpoint, summarize the viewpoint in 3 keywords max,\n",
    "                more keywords only if necessary to fully grasp the viewpoint. Viewpoint keywords\n",
    "                should be expressed as noun phrases that describe the viewpoint in a depersonalized manner.\n",
    "                For example, instead of “Supports Renewables”, the viewpoint keyword should be “Support for Renewables”.\n",
    "                Instead of “Believes in Traditional Energy”, the viewpoint keyword should be “Belief in Traditional Energy”.\n",
    "\n",
    "                If there are several viewpoints, summarize each viewpoint in 3 keywords max, more keywords only if\n",
    "                necessary to fully grasp the topic. Viewpoint keywords should be expressed as noun phrases that describe\n",
    "                the viewpoint in a depersonalized manner, as explained in the instruction for one viewpoint.\n",
    "        Step 4: Disregard viewpoints that are not relevant to the current topic or more relevant to another topic. Only if a viewpoint is equally relevant to multiple topics, include it under all relevant topics.\n",
    "        Step 5: Identify any linkages between viewpoints that build upon each other or propose solutions to identified issues. For instance, if a viewpoint such as 'Media literacy and critical thinking' is expressed as a solution to the issue identified in another viewpoint like 'Concerns about misinformation', classify it as a sub-viewpoint of the latter. Represent these sub-viewpoints appropriately within the hierarchical structure of the result dictionary.\n",
    "        Step 6: Identify viewpoints that convey essentially the same stance on the topic. For example, viewpoints like 'Lack of regulation and transparency' and 'Need for better regulation' express similar concerns regarding the need for increased regulation in the domain. In such cases, merge these viewpoints into a single unified viewpoint that encapsulates both perspectives. Ensure this is reflected in the summary of viewpoints in the result dictionary.\n",
    "        Step 7: Append the topics-dictionary with the identified and summarized viewpoints as sub-keys and the corresponding discussion excerpts as values.Format the dictionary in JSON-format.\n",
    "\n",
    "        Only include the appended dictionary in your response.\n",
    "\n",
    "        ```{transcript}```\n",
    "        \"\"\"\n",
    "        viewpoints = get_completion(prompt)\n",
    "        viewpoints_json = json.loads(viewpoints)\n",
    "        result.update(viewpoints_json)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e7e93a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only topics and viewpoints, without excerpts\n",
    "\n",
    "def get_viewpoints_by_topic(topics,transcript):\n",
    "    prompt = f\"\"\"\n",
    "    You are an assistant for group discussions, specialized on keeping track and documenting the discussion,\n",
    "    that is, the topics discussed, the viewpoints/positions on each topic and the arguments/explanations given in support of each viewpoint.\n",
    "    For each main topic in \"{topics}\", analyse the corresponding excerpt from the below discussion transcript, deliminted by triple backticks.\n",
    "    Your task is to identify all the viewpoints expressed on the topic.\n",
    "\n",
    "    Proceed according to the following steps:\n",
    "\n",
    "    Step 1: Are there one or several viewpoints being expressed in the excerpt?\n",
    "                A \"viewpoint\" refers to \"one's perspective of opinion on a particular topic\".\n",
    "    Step 2: If there is only one viewpoint, summarize the viewpoint in 3 keywords max,\n",
    "                more keywords only if necessary to fully grasp the viewpoint. Viewpoint keywords\n",
    "                should be expressed as noun phrases that describe the viewpoint in a depersonalized manner.\n",
    "                For example, instead of “Supports Renewables”, the viewpoint keyword should be “Support for Renewables”.\n",
    "                Instead of “Believes in Traditional Energy”, the viewpoint keyword should be “Belief in Traditional Energy”.\n",
    "\n",
    "                If there are several viewpoints, summarize each viewpoint in 3 keywords max, more keywords only if\n",
    "                necessary to fully grasp the topic. Viewpoint keywords should be expressed as noun phrases that describe\n",
    "                the viewpoint in a depersonalized manner, as explained in the instruction for one viewpoint.\n",
    "    Step 3: Disregard viewpoints that are not relevant to the current topic or more relevant to another topic. Only if a viewpoint is equally relevant to multiple topics, include it under all relevant topics.\n",
    "    Step 4: Identify any linkages between viewpoints that build upon each other or propose solutions to identified issues. For instance, if a viewpoint such as 'Media literacy and critical thinking' is expressed as a solution to the issue identified in another viewpoint like 'Concerns about misinformation', classify it as a sub-viewpoint of the latter. Represent these sub-viewpoints appropriately within the hierarchical structure of the result dictionary.\n",
    "    Step 5: Identify viewpoints that convey essentially the same stance on the topic. For example, viewpoints like 'Lack of regulation and transparency' and 'Need for better regulation' express similar concerns regarding the need for increased regulation in the domain. In such cases, merge these viewpoints into a single unified viewpoint that encapsulates both perspectives. Ensure this is reflected in the summary of viewpoints in the result dictionary.\n",
    "    Step 6: Append the topics-dictionary with the identified and summarized viewpoints as sub-keys.Format the dictionary in JSON-format.\n",
    "\n",
    "    Only include the appended dictionary in your response.\n",
    "\n",
    "    ```{transcript}```\n",
    "    \"\"\"\n",
    "    viewpoints = get_completion(prompt)\n",
    "    viewpoints_json = json.loads(viewpoints)\n",
    "    return viewpoints_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "720fa600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'main_topic': 'Rising sea levels and mitigation efforts for coastal cities', 'viewpoints': {'Relocation to safer locations': {}, 'Increased preparedness for extreme weather events': {}, 'Lobbying for robust government measures': {}, 'Reducing carbon footprint': {'Investing in green technologies': {}, 'Shifting to cleaner production methods': {}}, 'Improving brand image': {}, 'Comprehensive plan involving multiple teams': {}, 'Engaging with local communities': {}}}\n",
      "Execution time: 19.825178146362305 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "viewpoints = get_viewpoints_by_topic(topics,transcript)\n",
    "end_time = time.time()\n",
    "print(viewpoints)\n",
    "print(f\"Execution time: {end_time - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "21912a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_diagram(d, level=0):\n",
    "    result = \"\"\n",
    "    for key, value in d.items():\n",
    "        result += \"    \" * level + str(key) + \"\\n\"\n",
    "        if isinstance(value, dict):\n",
    "            result += tree_diagram(value, level + 1)\n",
    "        else:\n",
    "            result += \"    \" * (level + 1) + str(value) + \"\\n\"\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ed256612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "main_topic\n",
      "    Rising sea levels and mitigation efforts for coastal cities\n",
      "viewpoints\n",
      "    Relocation to safer locations\n",
      "    Increased preparedness for extreme weather events\n",
      "    Lobbying for robust government measures\n",
      "    Reducing carbon footprint\n",
      "        Investing in green technologies\n",
      "        Shifting to cleaner production methods\n",
      "    Improving brand image\n",
      "    Comprehensive plan involving multiple teams\n",
      "    Engaging with local communities\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tree_diagram(viewpoints))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bc44296d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from anytree import Node, RenderTree\n",
    "\n",
    "def json_to_tree(viewpoints_by_topics):\n",
    "    def process_viewpoint(name, viewpoint, parent=None):\n",
    "        node = Node(name, parent=parent)\n",
    "        if isinstance(viewpoint, dict):\n",
    "            for sub_viewpoint, content in viewpoint.items():\n",
    "                process_viewpoint(sub_viewpoint, content, parent=node)\n",
    "        else:\n",
    "            Node(viewpoint, parent=node)\n",
    "        return node\n",
    "\n",
    "    for topic, viewpoints in viewpoints_by_topics.items():\n",
    "        topic_node = Node(topic)\n",
    "        for viewpoint, content in viewpoints.items():\n",
    "            process_viewpoint(viewpoint, content, parent=topic_node)\n",
    "        for pre, _, node in RenderTree(topic_node):\n",
    "            print(\"%s%s\" % (pre, node.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5d98d549",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mjson_to_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mviewpoints\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[42], line 15\u001b[0m, in \u001b[0;36mjson_to_tree\u001b[0;34m(viewpoints_by_topics)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m topic, viewpoints \u001b[38;5;129;01min\u001b[39;00m viewpoints_by_topics\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     14\u001b[0m     topic_node \u001b[38;5;241m=\u001b[39m Node(topic)\n\u001b[0;32m---> 15\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m viewpoint, content \u001b[38;5;129;01min\u001b[39;00m \u001b[43mviewpoints\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m():\n\u001b[1;32m     16\u001b[0m         process_viewpoint(viewpoint, content, parent\u001b[38;5;241m=\u001b[39mtopic_node)\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m pre, _, node \u001b[38;5;129;01min\u001b[39;00m RenderTree(topic_node):\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "json_to_tree(viewpoints)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295e385b",
   "metadata": {},
   "source": [
    "# Feature 3 - Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2c9d6c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#OLD\n",
    "# Function for getting completion from OpenAI instructing model to identify arguments per viewpoint based on output from get_viewpoints_by_topic\n",
    "def get_arguments_by_viewpoint(viewpoints_by_topic):\n",
    "    prompt = f\"\"\"\n",
    "        You are an assistant for group discussions, specialized on keeping track and documenting the discussion,\n",
    "        that is, the topics discussed, the viewpoints and sub-viewpoints on each topic and the arguments/explanations given in support of each viewpoint and sub-viewpoint.\n",
    "        For the dictionary {viewpoints_by_topic}, delimited by triple # below, loop through each viewpoint and sub-viewpoint to extract the arguments/explanations given in support of each viewpoint and sub-viewpoint from the corresponding discussion excerpt provided as value.\n",
    "        Your task is to identify all the arguments/explanations given in support of each viewpoint and sub-viewpoint, summarize the arguments/explanations and document them together with the corresponding discussion excerpt.\n",
    "\n",
    "        Proceed according to the following steps:\n",
    "        Step 1: Identify all the viewpoints, sub-viewpoints and corresponding discussion excerpts in the dictionary. The keys of the second-level sub-dictionary/dictionaries represent the viewpoints. If there are sub-viewpoints, they are recorded as keys of the third-level sub-dictionaries.\n",
    "                For example, in the below example, delimited by triple *, 'Powerful tool for engagement','Concerns about misinformation' and 'Echo chambers and bias reinforcement' viewpoints. 'Lack of regulation and transparency' and 'Media literacy and critical thinking' are sub-viewpoints belonging to the viewpoint 'Concerns about misinformation'. 'Participant 1: \"The role of social media...\" is the excerpt corresponding to the viewpoint 'Powerful tool for engagement'. 'Participant 2: \"I agree that social media provides...\" is the excerpt corresponding to the sub-viewpoint 'Lack of regulation and transparency.\n",
    "                    ***{{\n",
    "                    'Social media in political campaigns': {{\n",
    "                        'Powerful tool for engagement': 'Participant 1: \"The role of social media in political campaigns is a subject that has gained significant attention in recent years. It has become a powerful tool for politicians to engage with voters and spread their message.\"',\n",
    "                        'Concerns about misinformation': {{\n",
    "                            'Lack of regulation and transparency': 'Participant 2: \"I agree that social media provides a platform for political candidates to connect with a wider audience and mobilize support. However, the lack of regulation and transparency in political advertising on these platforms is a major issue that needs to be addressed.\"',\n",
    "                            'Media literacy and critical thinking': 'Participant 3: \"I believe that social media has democratized political discourse and allowed marginalized voices to be heard. It provides a platform for grassroots movements and enables citizens to participate in political discussions like never before. We should focus on educating users about media literacy and critical thinking to combat misinformation.\"'\n",
    "                        }},\n",
    "                        'Echo chambers and bias reinforcement': 'Participant 4: \"While social media has its benefits, the algorithms used by these platforms tend to create echo chambers and reinforce existing biases. We need better regulation to ensure that diverse viewpoints are represented and to prevent the manipulation of public opinion through targeted content.\"'\n",
    "                        }},\n",
    "                    'Revamping annual festival': {{\n",
    "                        'Incorporating local talent': 'Yeah, we can incorporate more local talent, add a stage for local bands.',\n",
    "                        'Showcasing regional cuisine': 'And more food stalls. Our region is known for its cuisine, we can showcase that.',\n",
    "                        'Promoting local crafts': 'Festivals are a great place to promote local crafts too. We have a rich tradition here.',\n",
    "                        'Sustainability focus': 'We should also think about sustainability. We can minimize waste and promote recycling.',\n",
    "                        'Partnering with local businesses': 'What about partnering with local businesses? They can sponsor the event.',\n",
    "                        'Family activities': 'And we can organize workshops and competitions for kids. Involving families is important.',\n",
    "                        'Stronger marketing strategy': 'Finally, we need to get the word out. A stronger marketing strategy maybe?',\n",
    "                        'Engaging local influencers': 'How about reaching out to local influencers? They can promote the event on social media.'\n",
    "                        }}***\n",
    "\n",
    "       Step 2: For each identified viewpoint or sub-viewpoint, extract all the argument given in support of the viewpoint/sub-viewpoint from the corresponding discussion excerpts.\n",
    "               An \"argument\" refers to a statement or series of statements in support of a viewpoint expressed on a discussion topic.\n",
    "               It can consist a series of statements, facts, or any kind of explanation or justification intended to develop or support a point of view.\n",
    "               It is often structured as follows: a claim backed up with evidence, facts, and examples.\n",
    "\n",
    "       Step 3: Summarize all the arguments per viewpoint or sub-viewpoint in one to three sentences.Make the summary long enough to capture the full complexity of the argument and make it understandable for an outsider unfamiliar with the discussion, but shorter than the corresponding discussion excerpt. Arguments should be expressed as noun phrases that describe the argument in a depersonalized manner.\n",
    "               For example, instead of “Argues renewables are bad, because windmills destroy biodiversity”, the argument summary should be “Renewables are bad, because wind farms negatively impact biodiversity”.\n",
    "\n",
    "        Step 4: Revise the dictionary {viewpoints_by_topic} in the following way:\n",
    "                - Erase the discussion excerpts corresponding to each viewpoint or sub-viewpoint\n",
    "                - In place of the erased discussion excerpts, insert a new sub-dictionary with all the argument summaries in support of the respective viewpoint or sub-viewpoint as keys and corresponding discussion excerpts as values.\n",
    "\n",
    "        Only include the appended dictionary in your response.\n",
    "\n",
    "        ###{viewpoints_by_topic}###\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    arguments = get_completion(prompt)\n",
    "\n",
    "    prompt = f\"\"\"Given the following Python-style dictionary {arguments}, please convert it into a properly\n",
    "    formatted JSON object.\n",
    "    \"\"\"\n",
    "    arguments_json = get_completion(prompt)\n",
    "    arguments_json = json.loads(arguments_json)\n",
    "\n",
    "    return arguments_json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f6d1148e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NEW arguments without excerpts\n",
    "# Function for getting completion from OpenAI instructing model to identify arguments per viewpoint based on output from get_viewpoints_by_topic\n",
    "def get_arguments_by_viewpoint(viewpoints, transcript):\n",
    "    prompt = f\"\"\"\n",
    "        You are an assistant for group discussions, specialized on keeping track and documenting the discussion,\n",
    "        that is, the topics discussed, the viewpoints and sub-viewpoints on each topic and the arguments/explanations given in support of each viewpoint and sub-viewpoint.\n",
    "        Loop through each viewpoint and sub-viewpoint {viewpoints} and extract the arguments/explanations given in support of each viewpoint and sub-viewpoint from the corresponding excerpt in the below discussion transcript, delimited by triple hashtags.\n",
    "        Your task is to identify all the arguments/explanations given in support of each viewpoint and sub-viewpoint, summarize the arguments/explanations and document them.\n",
    "\n",
    "        Proceed according to the following steps:\n",
    "        Step 1: Identify all the viewpoints and sub-viewpoints in {viewpoints}. \n",
    "        \n",
    "        Step 2: For each identified viewpoint and sub-viewpoint, extract all the argument given in support of the viewpoint/sub-viewpoint from the corresponding excerpt in the below discussion transcript.\n",
    "               An \"argument\" refers to a statement or series of statements in support of a viewpoint expressed on a discussion topic.\n",
    "               It can consist a series of statements, facts, or any kind of explanation or justification intended to develop or support a point of view.\n",
    "               It is often structured as follows: a claim backed up with evidence, facts, and examples.\n",
    "        \n",
    "        Step 3: Summarize all the arguments per viewpoint or sub-viewpoint in one or multiple sentences.Make the summary long enough to capture the full complexity of the argument and make it understandable for an outsider unfamiliar with the discussion, but shorter than the corresponding discussion excerpt. Arguments should be expressed as noun phrases that describe the argument in a depersonalized manner.\n",
    "               For example, instead of “Argues renewables are bad, because windmills destroy biodiversity”, the argument summary should be “Renewables are bad, because wind farms negatively impact biodiversity”.\n",
    "\n",
    "        Step 4: Revise the dictionary {viewpoints} in the following way:\n",
    "                - For each viewpoint and sub-viewpoint, insert a new sub-dictionary with all the argument summaries in support of the respective viewpoint or sub-viewpoint. Format the dictionary in JSON-format.\n",
    "\n",
    "        Only include the appended dictionary in your response.\n",
    "\n",
    "        ###{transcript}###\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    arguments = get_completion(prompt)\n",
    "    arguments_json = json.loads(arguments)\n",
    "\n",
    "    return arguments_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e535b5b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'main_topic': 'Rising sea levels and mitigation efforts for coastal cities', 'viewpoints': {'Relocation to safer locations': {'arguments': ['Proactive mitigation efforts', 'Reduced risk from rising sea levels'], 'argument_summaries': ['Being proactive in addressing the threat to coastal cities', 'Minimizing risk by moving operations inland']}, 'Increased preparedness for extreme weather events': {'arguments': ['Reinforcing infrastructure', 'Developing contingency plans'], 'argument_summaries': ['Strengthening infrastructure to withstand extreme weather', 'Having plans in place to deal with potential disasters']}, 'Lobbying for robust government measures': {'arguments': ['Addressing a national issue', 'Collaborative efforts for greater impact'], 'argument_summaries': ['Recognizing the need for government intervention', 'Working together for more effective solutions']}, 'Reducing carbon footprint': {'Investing in green technologies': {'arguments': ['Corporate responsibility', 'Environmental benefits'], 'argument_summaries': [\"Taking responsibility for the company's environmental impact\", 'Contributing to a cleaner environment through green investments']}, 'Shifting to cleaner production methods': {'arguments': ['Reduced environmental impact', 'Sustainable operations'], 'argument_summaries': [\"Lowering the company's negative impact on the environment\", 'Implementing sustainable production practices']}}, 'Improving brand image': {'arguments': ['Portraying as environmentally-conscious corporation', 'Attracting eco-conscious customers'], 'argument_summaries': ['Presenting the company as responsible and eco-friendly', 'Appealing to environmentally-aware consumers']}, 'Comprehensive plan involving multiple teams': {'arguments': ['Collaborative approach', 'Involving risk management, PR, and other teams'], 'argument_summaries': ['Developing a well-rounded strategy with input from various departments', 'Incorporating diverse perspectives for a more effective plan']}, 'Engaging with local communities': {'arguments': ['Inclusive decision-making', 'Addressing community concerns'], 'argument_summaries': ['Involving local communities in the decision-making process', 'Taking into account the needs and concerns of affected communities']}}}\n",
      "Execution time: 104.95634722709656 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "arguments = get_arguments_by_viewpoint(viewpoints,transcript)\n",
    "end_time = time.time()\n",
    "print(arguments)\n",
    "print(f\"Execution time: {end_time - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "18465cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "main_topic\n",
      "    Rising sea levels and mitigation efforts for coastal cities\n",
      "viewpoints\n",
      "    Relocation to safer locations\n",
      "        arguments\n",
      "            ['Proactive mitigation efforts', 'Reduced risk from rising sea levels']\n",
      "        argument_summaries\n",
      "            ['Being proactive in addressing the threat to coastal cities', 'Minimizing risk by moving operations inland']\n",
      "    Increased preparedness for extreme weather events\n",
      "        arguments\n",
      "            ['Reinforcing infrastructure', 'Developing contingency plans']\n",
      "        argument_summaries\n",
      "            ['Strengthening infrastructure to withstand extreme weather', 'Having plans in place to deal with potential disasters']\n",
      "    Lobbying for robust government measures\n",
      "        arguments\n",
      "            ['Addressing a national issue', 'Collaborative efforts for greater impact']\n",
      "        argument_summaries\n",
      "            ['Recognizing the need for government intervention', 'Working together for more effective solutions']\n",
      "    Reducing carbon footprint\n",
      "        Investing in green technologies\n",
      "            arguments\n",
      "                ['Corporate responsibility', 'Environmental benefits']\n",
      "            argument_summaries\n",
      "                [\"Taking responsibility for the company's environmental impact\", 'Contributing to a cleaner environment through green investments']\n",
      "        Shifting to cleaner production methods\n",
      "            arguments\n",
      "                ['Reduced environmental impact', 'Sustainable operations']\n",
      "            argument_summaries\n",
      "                [\"Lowering the company's negative impact on the environment\", 'Implementing sustainable production practices']\n",
      "    Improving brand image\n",
      "        arguments\n",
      "            ['Portraying as environmentally-conscious corporation', 'Attracting eco-conscious customers']\n",
      "        argument_summaries\n",
      "            ['Presenting the company as responsible and eco-friendly', 'Appealing to environmentally-aware consumers']\n",
      "    Comprehensive plan involving multiple teams\n",
      "        arguments\n",
      "            ['Collaborative approach', 'Involving risk management, PR, and other teams']\n",
      "        argument_summaries\n",
      "            ['Developing a well-rounded strategy with input from various departments', 'Incorporating diverse perspectives for a more effective plan']\n",
      "    Engaging with local communities\n",
      "        arguments\n",
      "            ['Inclusive decision-making', 'Addressing community concerns']\n",
      "        argument_summaries\n",
      "            ['Involving local communities in the decision-making process', 'Taking into account the needs and concerns of affected communities']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tree_diagram(arguments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f559af3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a81fe03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735f724f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2214924a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
